{"cells":[{"cell_type":"markdown","metadata":{"id":"fEUqaxCDQA_j"},"source":["# Transfer Learning and Regularization\n","\n","Proprietary material - Under Creative Commons 4.0 licence CC-BY-NC-ND https://creativecommons.org/licenses/by-nc-nd/4.0/\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Transfer Learning\n","\n","## The Current State of Deep Learning Training\n","\n","The most recent breakthroughs in DL have also come with the predictable problem of increased computational power and time needed in training. \n","\n","There is a constant balance between the designing of new operators and techniques that reduce the computing costs and the design of larger and larger architectures that produces better and better performances. \n","\n","<img src=\"CNN_Backbones_Complexity.png\">\n","<img src=\"CNN_Backbones_Cost.png\">\n","\n","Is there a way to train complex architectures for our applications with easy to access hardware in a reasonable time?\n","\n","Nowadays there are some services that rent servers like Google Cloud and AWS that can allow us to train our models in several GPUs. Still, being able to save in training time will reduce our cost and allow us to iterate more on our model. \n","\n","## Initial Approach\n","\n","In the internet there is already a multitude of neural nets trained in huge datasets like ImageNet, COCO, Pascal and many more with great performances.\n","\n","This networks could have taken weeks of training in very powerful GPUs, so replicating it could take us months or large amounts of money to replicate. \n","\n","Instead of repeating the training process, let's use these trained weights as the starting point for our training. Effectively ‘transferring’ what they learned to our model.\n","\n","This could also help in cases where we don't have many samples in our dataset.\n","\n","Let's see how we can transfer the knowledge from one net to another with an example.\n","\n","## Transfer Example\n","\n","\n","Let's suppose we are tasked with the objective of training a classifier for four species of birds, but the amount of data that we have is not enough to train a CNN from scratch.\n","\n","Instead, lets download a model and its trained weights from the internet trained over a 1000 classes, like the following net:\n","\n","<img src=\"TransferLearning-Page-1.png\">\n","\n","To adapt it to our task we can adapt the last layer like so:\n","\n","<img src=\"TransferLearning-Page-2.png\">\n","\n","This allows the new layer to utilize the features extracted by the downloaded weights. But instead of using all the weights, we could just use the shallower layers that extract the lowest level of features like this: \n","\n","<img src=\"TransferLearning-Page-3.png\">\n","\n","Once again, this allows our model to use the feature extraction from the model we downloaded, but also allows it to find a higher level extractor for it's own task.\n","\n","But in case we needed a model larger than the one we downloaded, we can still grab the lower layers to use as feature extractors and just modify the deeper layers like so:\n","\n","<img src=\"TransferLearning-Page-4.png\">\n","\n","## Fine Tunning\n","\n","But what if we trained the whole model after loading the weights? \n","\n","This is called Fine Tunning, and is basically just training from a starting solution like this:\n","\n","<img src=\"TransferLearning-Page-5.png\">\n","\n","The idea is that the weights provide a great initialization for the weights of our optimization problem. Before appliing Finne Tunning is very important to reduce the learning rate of the optimizer. If you don't reduce it you might loss the found solution. \n","\n","Fine Tunning and Transfer Learning are not a one or the other ordeal. Usually is recommended to apply a bit of Fine Tunning after training with Transfer Learning to \"round\" the model. \n","\n","## Transfer Learning in CNNs\n","\n","Due to the general structure of CNNs they provide a great base for Transfer Learning. But it's important to understand it before applying it.\n","\n","<img src=\"TransferLearning-Page-6.png\">\n","\n","The Fully Connected (FC) part of a CNN is often discarded when using Transfer Learning, while keeping the convolutional layers.\n","\n","This is because the convolutional layers extract the features from the input.\n","\n","If extra layers are added, those have to be after the frozen layers, so the learned information is not lost.\n","\n","## How much to train\n","\n","The most difficult part of Transfer Learning is usually defining the best layers to freeze and train. There is no easy solution, but there are some rules of thumb that we can follow.\n","\n","<img src=\"TransferLearning-Page-7.png\">\n","<img src=\"TransferLearning-Page-8.png\">\n","\n","Usually, the less data we have and more different the task that the model was trained compared to our own then the more layers we need to train.\n","\n","For example, if we downloaded a model for face recognition, if we wanted to train a model for face mask detection we could get away with training fewer layers than if we wanted to use the same model for fruit classification."]},{"cell_type":"markdown","metadata":{},"source":["# Regularization\n","\n","With neural nets, a common problem that occurs is that the models tend to overfitt. As a reminder, let's go over a bit of overfitting and underfitting.\n","\n","## Over and Under Fitting\n","\n","\n","<img src=\"overunderfitting.png\">\n","\n","Source: Kaggle\n","\n","This figure shows the differences between underfitting an overfitting. Probably the easiest way to introduce regularization to our model is called \"early stopping\".\n","\n","## Early Stopping\n","\n","Early stopping is, as the names indicates, just stopping the training of the model early so it doesn't adjust too much to the training data.\n","\n","The best time to do early stopping is when the training loss or metrics keep going down but the validation loss starts to go up. An example of this behavior can be seen here:\n","\n","<img src=\"early.png\">\n","\n","Source: Kaggle\n","\n","## L1 and L2 Regularization\n","\n","The L1 and L2 regularization have a similar idea: Add a penalization to the weights of the model to avoid arriving to solutions that require very large weights. This avoids that model to finds very specific solutions that can;t generalize well. \n","\n","To apply L1 and L2 regularization you only need to add the following terms to the loss function:\n","\n","L1: \n","\n","$$\n","\\hat{L} = L + \\lambda \\sum^M |W_i|\n","$$\n","\n","L2:\n","\n","$$\n","\\hat{L} = L + \\lambda \\sum^M W^2_i\n","$$\n","\n","Here $L$ is our previous loss, $M$ or space of weights and $\\lambda$ a positive constant often called the regularization rate.\n","\n","The effects of applying L1 or L2 regularization to the solution can be seen in the following figure:\n","\n","<img src=\"l1l2reg.png\">\n","\n","We can see that the L1 solution is sparse, compared to the L2 solution that is not. This allows the L1 regularization to perform feature selection, by choosing which features multiply by 0 it removes them from propagating trough the rest of the model. \n","\n","Another advantage of L1 over L2 is that is usually more robust to outliers, but there are ways to fix this with L2 with other regularization techniques. The main advantage that L2 has over L1 is that is way less computational intensive to calculate and tends to optimize easier. \n","\n","## Dropout\n","\n","Dropout is the final regularization technique that we will cover today, but might be one of the most relevant. \n","\n","Similarly to the L1 regularization, it multiplies features by 0, but does this randomly to help the net find a more generalized solution. To help illustrate this let's look at an example.\n","\n","We start with a FC net with five inputs:\n","\n","<img src=\"TransferLearning-Page-9.png\">\n","\n","Then, for any epoch we turn off randomly some connections like so:\n","\n","<img src=\"TransferLearning-Page-10.png\">\n","\n","Because it's random the following epoch could have tw connections turned off like this:\n","\n","<img src=\"TransferLearning-Page-11.png\">\n","\n","The idea behind dropout is that this random disconnections allow the model to generalize the solution trough all the connections instead of letting just a couple of connections to be used.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_wN76PVZj7IX"},"source":["# Introduction\n","\n","This week we will cover the basics of how to apply Transfer Learning to a Neural Net in Keras."]},{"cell_type":"markdown","metadata":{"id":"Iv4sWqymQHCi"},"source":["Most, if not all the the big Deep Learning libraries come with some tools to apply Transfer Learning from another model. Some even include models trained and ready for deployment that can be used directly for Transfer Learning, and luckly for us, Keras includes that option."]},{"cell_type":"markdown","metadata":{"id":"-rfUA6QsnZHK"},"source":["## Layer Freezing"]},{"cell_type":"markdown","metadata":{"id":"p2KWyrtpchsG"},"source":["Before using Transfer Learning, its necessary to go over an intruduction on how to freeze a model layers and what does that mean."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IixFruqAy2KK"},"outputs":[],"source":["# Importing relevant libraries\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.applications.vgg16 import VGG16"]},{"cell_type":"markdown","metadata":{"id":"42AKtkAMgD1q"},"source":["First, lets load a Neural Net from the Keras library. \n","\n","The architecture is an Xception Net and trained in the ImageNet dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8706,"status":"ok","timestamp":1616972328442,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"GYL1yOe8P6KU","outputId":"195efa36-e70b-4e69-97c1-43dd87a91868"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 5s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["vgg_net = VGG16(weights='imagenet', input_shape=(224, 224, 3), include_top=True) \n","vgg_net.summary()"]},{"cell_type":"markdown","metadata":{"id":"QKqHjIjIzO-r"},"source":["A frozen layer in a model means that the layer weights wont be updated during training, so to apply transfer learning you have to control which layers need to be frozen or unfrozen before or in the middle of training."]},{"cell_type":"markdown","metadata":{"id":"jzAGmTXl5xp7"},"source":["To count the number of unfrozen or frozen weights, we can access the lists '*trainable\\_weights*' and  '*non\\_trainable\\_weights*' respectively.\n","\n","**Note:** Notice that the weights are 32, which is the double of the number of layers of the model (VGG16). This is because for each FC and Conv layer there is two weights (the kernel and bias)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6324,"status":"ok","timestamp":1616972328444,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"hMDzr22Ewg8z","outputId":"008f78ce-8bef-4e9a-801f-bd33db538349"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of weights: 32\n","Number of trainable weights: 32\n","Number of frozen weights: 0\n"]}],"source":["print(\"Number of weights:\", len(vgg_net.weights))\n","print(\"Number of trainable weights:\", len(vgg_net.trainable_weights))\n","print(\"Number of frozen weights:\", len(vgg_net.non_trainable_weights))"]},{"cell_type":"markdown","metadata":{"id":"W6ZvS_y5_Axs"},"source":["We can freeze a layer by setting the layer '*trainable*' to False.\n","As a test, lets freeze the layers 'block1\\_conv2' and 'block4\\_conv3' in the positions 3 and 13 of the layers list."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50cUVENvyfDv"},"outputs":[],"source":["vgg_net.layers[2].trainable = False\n","vgg_net.layers[13].trainable = False"]},{"cell_type":"markdown","metadata":{"id":"FA9aVqIeAz2q"},"source":["Now lets check that those layers are frozzen."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":833,"status":"ok","timestamp":1616972340620,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"XsbM0pWU_r6X","outputId":"87244761-9adc-4051-af99-266705b02069"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of weights: 32\n","Number of trainable weights: 28\n","Number of frozen weights: 4\n"]}],"source":["print(\"Number of weights:\", len(vgg_net.weights))\n","print(\"Number of trainable weights:\", len(vgg_net.trainable_weights))\n","print(\"Number of frozen weights:\", len(vgg_net.non_trainable_weights))"]},{"cell_type":"markdown","metadata":{"id":"GJeSGvnCEvI9"},"source":["Seting the trainable to False works on all the sublayers, so if we want to freeze all layers we can do this:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":802,"status":"ok","timestamp":1616972922930,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"g1VCbu84A7L2","outputId":"4ca5267d-069a-4645-df75-9de26567ff02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of weights: 32\n","Number of trainable weights: 0\n","Number of frozen weights: 32\n"]}],"source":["vgg_net.trainable = False\n","\n","print(\"Number of weights:\", len(vgg_net.weights))\n","print(\"Number of trainable weights:\", len(vgg_net.trainable_weights))\n","print(\"Number of frozen weights:\", len(vgg_net.non_trainable_weights))"]},{"cell_type":"markdown","metadata":{"id":"pZ5ex6NzGdkx"},"source":["The summary also indicates how many parametres can be trained in a model (at the bootom). "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":748,"status":"ok","timestamp":1616972981893,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"JrbL00h5GLzc","outputId":"7f7347c1-2abc-4e57-bd42-d79ff5245002"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 0\n","Non-trainable params: 138,357,544\n","_________________________________________________________________\n"]}],"source":["vgg_net.summary()"]},{"cell_type":"markdown","metadata":{"id":"nE_WBWEeHDoJ"},"source":["# Transfer Learning"]},{"cell_type":"markdown","metadata":{"id":"r-DVJ4GXIg40"},"source":["Now lets finally prepare our model to train with Transfer Learning!\n","\n","First, lets grab one of the CNNs that come with Keras with no FC layers at the end.\n","\n","This can be done by passing the 'include\\_top' aprameter as False."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1005,"status":"ok","timestamp":1616986852563,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"OXFVTFo0GaNt","outputId":"aed09567-0998-4b9b-dea7-93e4b647bbe4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["vgg_net = VGG16(weights='imagenet', input_shape=(224, 224, 3), include_top=False) \n","vgg_net.trainable = False\n","vgg_net.summary()"]},{"cell_type":"markdown","metadata":{"id":"00oy2eB-22Ce"},"source":["Now lets add a couple of FC layers on top. For now, lets asume our otput is a binary classifier for simplicity."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1651,"status":"ok","timestamp":1616986860013,"user":{"displayName":"JOSÉ IGNACIO DÍAZ","photoUrl":"","userId":"14360442081919567546"},"user_tz":180},"id":"0m4hN7w61sbQ","outputId":"8928db7f-5b24-47c4-8501-25697b987c1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 4096)              102764544 \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1024)              4195328   \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 1)                 1025      \n","=================================================================\n","Total params: 121,675,585\n","Trainable params: 106,960,897\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["from keras.models import Sequential \n","from keras.layers import Dense, Flatten\n","from keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(vgg_net)\n","model.add(Flatten())\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.Adam(),\n","              metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"kZTR_0d67Z2D"},"source":["Now we have our model ready for the training loop!\n","\n","But lets leave that for the problem ;)\n","\n","Before geting to that, try to keep in mind the following considerations:\n","\n","\n","\n","1.   To accelerate the training, you can extract the features from the data using the frozen layers and train the rest of the model using those features.\n","\n","2.   The previos point can't be used if you are using data augmentation douring the training, but it can be done beforehand.\n","\n","3.  At the end of the training, its recomended to apply a bit of Fine Tunning to the model, by unfreezing the model and reducing the learning rate.\n","\n","4.  You can't add new layers before the frozen layers. If you need to, Fine Tuning is the only option.\n","\n","5. When using a CNN for transfer Learning, remember to modify your data so it has the expected size for the model.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VO09NjVnLOgF"},"source":["## Exercise \n","\n","Lets build a cat vs dog image classifier with a CNN. For that, you are free to so as you want, but we recomend at leats some of the following steps:\n","\n","1. Download the data from this link https://www.kaggle.com/c/dogs-vs-cats/data. If you want to use some other dataset, you are free to do so.\n","\n","2. Explore the data, visualize some examples and check the size of the images.\n","\n","3.  Choose an architecture from https://keras.io/api/applications/ to your liking. \n","\n","4. Reshape the images to the same size. For this you can use OpenCV like this:\n","\n","\n","\n","```\n","import cv2\n","import os\n","\n","path = 'path tho directory'\n","image_paths = os.listdir(path)\n","\n","for file in image_paths:\n","    image = cv2.imread(os.path.join(path, file))\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\timage = cv2.resize(image, (224, 224))\n","\n","    ...\n","```\n","\n","Then you can save the images to a list or data structure inside the loop. Some files include their class in the name, so this loop offers a great oportunity to prepare the labels too.\n","\n","\n","\n","4. If the shape of the data is diferent to the ImageNet data, you need to reshape the input. For this you can add the parameter 'input\\_tensor' when loading the trained model. For example, for an input of 128x128:\n","\n","\n","\n","```\n","vgg_net = VGG16(weights=\"imagenet\", include_top=False,\n","\tinput_tensor=Input(shape=(128, 128, 3)))\n","```\n","\n","5. Freeze the model and add some new FC and Dropout layers with apropiate sizes. \n","\n","5. Separate the data into train and validation by 80% train and 20% validation. \n","\n","6. Train the model over the train data. Use the Adam optimizer and choose a loss apropiate to your problem. As an example, in case its a binary classifier use  Binary Cross Entropy.\n","\n","7. Optional: Unfreeze the model at the end and train once again the model using Fine Tuning.\n","\n","8. Analize the training time and the performance of the model in the test data. Optional: Share some of you results with the team and discuss about the architecture, loss and performace of your model. \n","\n","\n","We understand that some of this steps might be a bit complicated or unclear for some, so dont be afraid to ask questions to the team in the public channels or check the references for some guidance.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"CiTN8qnpKqxV"},"source":["## References\n","\n","\n","The oficial Keras Tutorial\n","\n","https://keras.io/guides/transfer_learning/\n","\n","List and examples of some architectures in Keras \n","\n","https://keras.io/api/applications/\n","\n","A great tutorial that goes deeper into Transfer Learning, but we recomend checking it out after being done with the exercise. And I trust you will.\n","\n","https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Transfer learning.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.9 (default, Jun 29 2022, 11:45:57) \n[GCC 8.4.0]"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
